from mainapp.models import Character, Worldbook, ChatSettings
import json


# def build_ai_request(user, character: Character, chat_settings: ChatSettings):
#     """
#     –§–æ—Ä–º—É—î JSON-–∑–∞–ø–∏—Ç –¥–ª—è –º–æ–¥–µ–ª—ñ –®–Ü (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π —ñ —á–∏—Ç–∞–±–µ–ª—å–Ω–∏–π).
#     """
#
#     # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ ChatSettings JSON
#     settings_data = {}
#     if chat_settings and chat_settings.json_file and hasattr(chat_settings.json_file, "path"):
#         try:
#             with open(chat_settings.json_file.path, "r", encoding="utf-8") as f:
#                 settings_data = json.load(f)
#         except Exception:
#             settings_data = {}
#
#     # –í–∏—Ç—è–≥—É—î–º–æ —è–¥—Ä–æ (core) —ñ —Å–∏—Å—Ç–µ–º–Ω—ñ –ø—Ä–æ–º–ø—Ç–∏
#     core_keys = {"max_tokens", "seed", "sampling"}
#     core_data = {k: settings_data[k] for k in core_keys if k in settings_data}
#     system_prompts = {k: v for k, v in settings_data.items() if k not in core_keys}
#
#     # 2. Character description
#     character_data = {
#         "name": character.name,
#         "description": character.description,
#         "scenario": character.scenario,
#         "initial_message": character.initial_message,
#         "creator_notes": character.creator_notes,
#     }
#
#     # 3. Chat history —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
#     chat_history = []
#     last_user_message = None
#     if character.chat_log_file and hasattr(character.chat_log_file, "path"):
#         try:
#             with open(character.chat_log_file.path, "r", encoding="utf-8") as f:
#                 messages = json.load(f)
#
#             # –ó–Ω–∞–π—Ç–∏ –≤—Å—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
#             user_messages = [msg for msg in messages if msg[0] == "user"]
#
#             if user_messages:
#                 last_user_message = user_messages[-1]  # –æ—Å—Ç–∞–Ω–Ω—î
#
#                 # ChatHistory = –æ—Å—Ç–∞–Ω–Ω—ñ 5 –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–Ω—ñ–º user
#                 last_user_index = messages.index(last_user_message)
#                 chat_history = messages[max(0, last_user_index - 5):last_user_index]
#
#         except Exception:
#             chat_history = []
#             last_user_message = None
#
#     # 4. User persona
#     user_persona = {
#         "persona_name": getattr(user, "persona_name", None),
#         "persona_description": getattr(user, "persona_description", None),
#         "name": getattr(user, "name", user.username),
#         "date_birth": user.date_birth.isoformat() if getattr(user, "date_birth", None) else None,
#     }
#
#     # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π JSON
#     ai_request = {
#         "Core": core_data,
#         "SystemPrompts": system_prompts,
#         "CharacterDescription": character_data,
#         "ChatHistory": chat_history,
#         "LastUserMessage": last_user_message,
#         "UserPersona": user_persona,
#     }
#
#     # üîπ –í–∏–≤—ñ–¥ —É –∫–æ–Ω—Å–æ–ª—å —É –∫—Ä–∞—Å–∏–≤–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ
#     #print("\n=== AI REQUEST JSON ===")
#     #print(json.dumps(ai_request, indent=4, ensure_ascii=False))
#     #print("=======================\n")
#
#     return ai_request

#=======================================

# def build_ai_request(user, character: Character, chat_settings: ChatSettings, worldbook_slug=None):
#     """
#     –§–æ—Ä–º—É—î JSON-–∑–∞–ø–∏—Ç –¥–ª—è –º–æ–¥–µ–ª—ñ –®–Ü (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π —ñ —á–∏—Ç–∞–±–µ–ª—å–Ω–∏–π).
#     """
#
#     # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ ChatSettings JSON
#     settings_data = {}
#     if chat_settings and chat_settings.json_file and hasattr(chat_settings.json_file, "path"):
#         try:
#             with open(chat_settings.json_file.path, "r", encoding="utf-8") as f:
#                 settings_data = json.load(f)
#         except Exception:
#             settings_data = {}
#
#     # –í–∏—Ç—è–≥—É—î–º–æ —è–¥—Ä–æ (core) —ñ —Å–∏—Å—Ç–µ–º–Ω—ñ –ø—Ä–æ–º–ø—Ç–∏
#     core_keys = {"max_tokens", "seed", "sampling"}
#     core_data = {k: settings_data[k] for k in core_keys if k in settings_data}
#     system_prompts = {k: v for k, v in settings_data.items() if k not in core_keys}
#
#     # 2. Character description
#     character_data = {
#         "name": character.name,
#         "description": character.description,
#         "scenario": character.scenario,
#         "initial_message": character.initial_message,
#         "creator_notes": character.creator_notes,
#     }
#
#     # 3. Chat history —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
#     chat_history = []
#     last_user_message = None
#     if character.chat_log_file and hasattr(character.chat_log_file, "path"):
#         try:
#             with open(character.chat_log_file.path, "r", encoding="utf-8") as f:
#                 messages = json.load(f)
#
#             user_messages = [msg for msg in messages if msg[0] == "user"]
#
#             if user_messages:
#                 last_user_message = user_messages[-1]
#
#                 last_user_index = messages.index(last_user_message)
#                 chat_history = messages[max(0, last_user_index - 5):last_user_index]
#
#         except Exception:
#             chat_history = []
#             last_user_message = None
#
#     # 4. User persona
#     user_persona = {
#         "persona_name": getattr(user, "persona_name", None),
#         "persona_description": getattr(user, "persona_description", None),
#         "name": getattr(user, "name", user.username),
#         "date_birth": user.date_birth.isoformat() if getattr(user, "date_birth", None) else None,
#     }
#
#     # 5. Worldbook matches
#     worldbook_matches = []
#     if last_user_message and worldbook_slug:
#         try:
#             worldbook_matches = get_worldbook_matches(last_user_message[2], worldbook_slug, top_k=5)
#         except Exception as e:
#             print(f"Worldbook match error: {e}")
#             worldbook_matches = []
#
#     # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π JSON
#     ai_request = {
#         "Core": core_data,
#         "SystemPrompts": system_prompts,
#         "CharacterDescription": character_data,
#         "ChatHistory": chat_history,
#         "LastUserMessage": last_user_message,
#         "UserPersona": user_persona,
#         "WorldbookMatches": worldbook_matches,   # üîπ –Ω–æ–≤–∏–π –±–ª–æ–∫
#     }
#     print("–ó –§–£–ù–ö–¶–Ü–á")
#     print(ai_request)
#
#
#     return ai_request


import io
import json
import numpy as np
from sentence_transformers import util

# def get_worldbook_matches(message, worldbook_slug, top_k=5):
#     print("INFO====================")
#     print(message, worldbook_slug)
#
#     try:
#         wb = Worldbook.objects.get(slug=worldbook_slug)
#     except Worldbook.DoesNotExist:
#         return []
#
#     if not wb.json_file:
#         return []
#
#     # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —Ñ–∞–π–ª —è–∫ —Ç–µ–∫—Å—Ç–æ–≤–∏–π
#     with wb.json_file.open('rb') as f:
#         text = io.TextIOWrapper(f, encoding='utf-8').read()
#         data = json.loads(text)
#
#     keys = list(data.keys())
#     values = list(data.values())
#
#     # –°—Ç–≤–æ—Ä—é—î–º–æ –µ–º–±–µ–¥—ñ–Ω–≥–∏ –¥–ª—è –∫–ª—é—á—ñ–≤
#     key_embeddings = model.encode(keys, convert_to_tensor=True)
#     message_embedding = model.encode(message, convert_to_tensor=True)
#
#     # –û–±—á–∏—Å–ª—é—î–º–æ —Å—Ö–æ–∂—ñ—Å—Ç—å –∫–æ—Å–∏–Ω—É—Å–æ–º
#     cos_scores = util.cos_sim(message_embedding, key_embeddings)[0]
#
#     # –í–∏–±–∏—Ä–∞—î–º–æ —Ç–æ–ø-k –Ω–∞–π–±—ñ–ª—å—à —Å—Ö–æ–∂–∏—Ö
#     top_results = np.argpartition(-cos_scores, range(top_k))[:top_k]
#
#     results = []
#     for idx in top_results:
#         results.append({
#             "key": keys[idx],
#             "value": values[idx],
#             "similarity": float(cos_scores[idx])
#         })
#
#     # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é
#     results = sorted(results, key=lambda x: x['similarity'], reverse=True)
#
#     return results
#

# def get_worldbook_matches(message, worldbook_slug, top_k=5, similarity_threshold=0.1):
#     print("INFO-----------",message, worldbook_slug)
#     try:
#         wb = Worldbook.objects.get(slug=worldbook_slug)
#     except Worldbook.DoesNotExist:
#         print("Worldbook.DoesNotExist")
#         return {"AdditionalContext": []}
#
#     if not wb.json_file:
#         print("not wb.json_file")
#         return {"AdditionalContext": []}
#
#     # –ß–∏—Ç–∞—î–º–æ JSON —Ñ–∞–π–ª
#     with wb.json_file.open('rb') as f:
#         text = io.TextIOWrapper(f, encoding='utf-8').read()
#         data = json.loads(text)
#
#     # –ë–µ—Ä–µ–º–æ –ª–∏—à–µ –ø–∞—Ä–∏ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–Ω—è, —â–æ —î "—Ç–µ–∫—Å—Ç–æ–≤–∏–º–∏"
#     key_value_pairs = {k: v for k, v in data.items() if isinstance(v, (str, int, float))}
#
#     if not key_value_pairs:
#         print("not key_value_pairs")
#         return {"AdditionalContext": []}
#
#     keys = list(key_value_pairs.keys())
#     values = list(key_value_pairs.values())
#
#     print("KeysVALUES", keys, values)
#
#     # –°—Ç–≤–æ—Ä—é—î–º–æ –µ–º–±–µ–¥—ñ–Ω–≥–∏
#     key_embeddings = model.encode(keys, convert_to_tensor=True)
#     message_embedding = model.encode(message, convert_to_tensor=True)
#
#     # –ö–æ—Å–∏–Ω—É—Å–Ω–∞ —Å—Ö–æ–∂—ñ—Å—Ç—å
#     cos_scores = util.cos_sim(message_embedding, key_embeddings)[0]
#
#     results = []
#
#     # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ø–∏—Å–æ–∫ (index, score) –¥–ª—è —Ç–∏—Ö, —â–æ –ø–µ—Ä–µ–≤–∏—â—É—é—Ç—å –ø–æ—Ä—ñ–≥ 0.7
#     valid_scores = [(idx, float(score)) for idx, score in enumerate(cos_scores) if score > 0.7]
#
#     # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é
#     valid_scores.sort(key=lambda x: x[1], reverse=True)
#
#     # –ë–µ—Ä–µ–º–æ –ª–∏—à–µ —Ç–æ–ø-K
#     top_indices = [idx for idx, _ in valid_scores[:top_k]]
#
#     # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–Ω—è
#     for idx in top_indices:
#         results.append({
#             "key": keys[idx],
#             "value": values[idx]
#         })
#
#     return results

#=======================================================

# from openai import OpenAI
# import numpy as np
#
# # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç–∞ OpenAI
# client = OpenAI(api_key="YOUR_OPENAI_API_KEY")  # –∞–±–æ —á–µ—Ä–µ–∑ env OPENAI_API_KEY
#
# def get_similar_keys(text, keywords, similarity_threshold=0.7):
#     """
#     text: str, –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π —Ç–µ–∫—Å—Ç
#     keywords: list[str], —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–æ–≤–∏—Ö —Å–ª—ñ–≤
#     similarity_threshold: float, –ø–æ—Ä—ñ–≥ —Å—Ö–æ–∂–æ—Å—Ç—ñ
#     """
#     # –û—Ç—Ä–∏–º—É—î–º–æ embedding –¥–ª—è —Ç–µ–∫—Å—Ç—É
#     text_embedding = client.embeddings.create(
#         model="text-embedding-3-small",
#         input=text
#     )['data'][0]['embedding']
#
#     # –û—Ç—Ä–∏–º—É—î–º–æ embedding –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–ª—é—á–∞
#     key_embeddings = client.embeddings.create(
#         model="text-embedding-3-small",
#         input=keywords
#     )['data']
#
#     # –ö–æ—Å–∏–Ω—É—Å–Ω–∞ —Å—Ö–æ–∂—ñ—Å—Ç—å
#     def cosine_sim(a, b):
#         a = np.array(a)
#         b = np.array(b)
#         return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
#
#     similar_keys = []
#     for idx, k_emb in enumerate(key_embeddings):
#         sim = cosine_sim(text_embedding, k_emb['embedding'])
#         if sim >= similarity_threshold:
#             similar_keys.append(keywords[idx])
#
#     return similar_keys
#
# # --- –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è ---
# text = "I love eating pasta and fresh bread with poppy seeds"
# keywords = ["–±—É–ª–æ—á–∫–∞ –∑ –º–∞–∫–æ–º", "pasta", "cheese", "milk", "bread"]
#
# matches = get_similar_keys(text, keywords, similarity_threshold=0.6)
# print(matches)

#=====================================================




def get_worldbook_matches(message, worldbook_slug, top_k=5, similarity_threshold=0.01):
    print("INFO-----------", message, worldbook_slug)

    try:
        wb = Worldbook.objects.get(slug=worldbook_slug)
    except Worldbook.DoesNotExist:
        print("Worldbook.DoesNotExist")
        return {"AdditionalContext": []}

    if not wb.json_file:
        print("not wb.json_file")
        return {"AdditionalContext": []}

    # –ß–∏—Ç–∞—î–º–æ JSON —Ñ–∞–π–ª
    with wb.json_file.open('rb') as f:
        text = io.TextIOWrapper(f, encoding='utf-8').read()
        data = json.loads(text)

    # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –ø–∞—Ä–∏ key/value –∑ –≤–µ—Ä—Ö–Ω—å–æ–≥–æ —Ä—ñ–≤–Ω—è —Ç–∞ –∑ entries
    keys = []
    values = []

    # –í–µ—Ä—Ö–Ω—ñ–π —Ä—ñ–≤–µ–Ω—å
    for k, v in data.items():
        if k == "entries":
            continue  # –æ–±—Ä–æ–±–∏–º–æ –æ–∫—Ä–µ–º–æ
        keys.append(k)
        values.append(v)

    # –í–∫–ª–∞–¥–µ–Ω–∏–π —Å–ø–∏—Å–æ–∫ entries
    for entry in data.get("entries", []):
        if "key" in entry and "value" in entry:
            keys.append(entry["key"])
            values.append(entry["value"])

    if not keys:
        return {"AdditionalContext": []}

    print("Keys:", keys)
    print("Values:", values)

    # –°—Ç–≤–æ—Ä—é—î–º–æ –µ–º–±–µ–¥—ñ–Ω–≥–∏
    key_embeddings = model.encode(keys, convert_to_tensor=True)
    message_embedding = model.encode(message, convert_to_tensor=True)

    # –ö–æ—Å–∏–Ω—É—Å–Ω–∞ —Å—Ö–æ–∂—ñ—Å—Ç—å
    cos_scores = util.cos_sim(message_embedding, key_embeddings)[0]

    # –í–∏–±–∏—Ä–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏ –∑ cos_score > similarity_threshold
    valid_scores = [(idx, float(score)) for idx, score in enumerate(cos_scores) if score > similarity_threshold]

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é
    valid_scores.sort(key=lambda x: x[1], reverse=True)

    # –ë–µ—Ä–µ–º–æ —Ç–æ–ø-K
    top_indices = [idx for idx, _ in valid_scores[:top_k]]

    # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–Ω—è
    results = [{"key": keys[idx], "value": values[idx]} for idx in top_indices]

    return results


def build_ai_request(user, character: Character, chat_settings: ChatSettings, worldbook_slug=None, message: str = None):
    """
    –§–æ—Ä–º—É—î JSON-–∑–∞–ø–∏—Ç –¥–ª—è –º–æ–¥–µ–ª—ñ –®–Ü (—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π —ñ —á–∏—Ç–∞–±–µ–ª—å–Ω–∏–π).
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î message —è–∫ –æ—Å—Ç–∞–Ω–Ω—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.
    –Ø–∫—â–æ message=None, –ø—ñ–¥–≤–∞–Ω—Ç–∞–∂—É—î –æ—Å—Ç–∞–Ω–Ω—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ —Ñ–∞–π–ª—É —á–∞—Ç—É.
    """

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ ChatSettings JSON
    settings_data = {}
    if chat_settings and chat_settings.json_file and hasattr(chat_settings.json_file, "path"):
        try:
            with open(chat_settings.json_file.path, "r", encoding="utf-8") as f:
                settings_data = json.load(f)
        except Exception:
            settings_data = {}

    # –í–∏—Ç—è–≥—É—î–º–æ —è–¥—Ä–æ (core) —ñ —Å–∏—Å—Ç–µ–º–Ω—ñ –ø—Ä–æ–º–ø—Ç–∏
    core_keys = {"max_tokens", "seed", "sampling"}
    core_data = {k: settings_data[k] for k in core_keys if k in settings_data}
    system_prompts = {k: v for k, v in settings_data.items() if k not in core_keys}

    # 2. Character description
    character_data = {
        "name": character.name,
        "description": character.description,
        "scenario": character.scenario,
        "initial_message": character.initial_message,
        "creator_notes": character.creator_notes,
    }

    # 3. Chat history —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    chat_history = []
    last_user_message = None

    if message is not None:
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä–µ–¥–∞–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        last_user_message = ("user", "now", message, "neutral")  # –º–æ–∂–Ω–∞ –∑–∞–º—ñ–Ω–∏—Ç–∏ "now" –Ω–∞ datetime.now().strftime("%H:%M")
        chat_history = []  # –Ω–µ –±–µ—Ä–µ–º–æ —ñ—Å—Ç–æ—Ä—ñ—é –∑ —Ñ–∞–π–ª—É, –∞–±–æ –º–æ–∂–Ω–∞ –ø–µ—Ä–µ–¥–∞—Ç–∏ —á–∞—Å—Ç–∏–Ω—É —ñ—Å—Ç–æ—Ä—ñ—ó –∑ messages, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
    elif character.chat_log_file and hasattr(character.chat_log_file, "path"):
        try:
            with open(character.chat_log_file.path, "r", encoding="utf-8") as f:
                messages = json.load(f)

            user_messages = [msg for msg in messages if msg[0] == "user"]

            if user_messages:
                last_user_message = user_messages[-1]

                last_user_index = messages.index(last_user_message)
                chat_history = messages[max(0, last_user_index - 5):last_user_index]

        except Exception:
            chat_history = []
            last_user_message = None

    # 4. User persona
    user_persona = {
        "persona_name": getattr(user, "persona_name", None),
        "persona_description": getattr(user, "persona_description", None),
        "name": getattr(user, "name", user.username),
        "date_birth": user.date_birth.isoformat() if getattr(user, "date_birth", None) else None,
    }

    # 5. Worldbook matches
    worldbook_matches = []
    print("LAST_USER_MESSAGE", last_user_message)
    if last_user_message and worldbook_slug:
        try:
            worldbook_matches = get_worldbook_matches(last_user_message[2], worldbook_slug, top_k=5)
        except Exception as e:
            print(f"Worldbook match error: {e}")
            worldbook_matches = []

    # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π JSON
    ai_request = {
        "Core": core_data,
        "SystemPrompts": system_prompts,
        "CharacterDescription": character_data,
        "ChatHistory": chat_history,
        "LastUserMessage": last_user_message,
        "UserPersona": user_persona,
        "AdditionalContext": worldbook_matches,
    }


    print(ai_request)
    return ai_request



import json
import numpy as np
from sentence_transformers import SentenceTransformer, util
from .models import Worldbook

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –ø–æ—à—É–∫—É
model = SentenceTransformer('all-MiniLM-L6-v2')


# def get_worldbook_matches(message, worldbook_slug, top_k=5):
#     """
#     –ü–æ—à—É–∫ –Ω–∞–π–±—ñ–ª—å—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –∫–ª—é—á—ñ–≤ —É worldbook –¥–ª—è –∑–∞–¥–∞–Ω–æ–≥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.
#
#     :param message: —Ä—è–¥–æ–∫, —â–æ –º—ñ—Å—Ç–∏—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
#     :param worldbook_slug: slug –æ–±—Ä–∞–Ω–æ–≥–æ worldbook
#     :param top_k: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–∞–π–±—ñ–ª—å—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
#     :return: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤ {key, value, similarity}
#     """
#     print("INFO====================")
#     print(message, worldbook_slug)
#
#     try:
#         wb = Worldbook.objects.get(slug=worldbook_slug)
#     except Worldbook.DoesNotExist:
#         return []
#
#     if not wb.json_file:
#         return []
#
#     # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è JSON
#     wb.json_file.open('r', encoding='utf-8')
#     data = json.load(wb.json_file)
#     wb.json_file.close()
#
#     keys = list(data.keys())
#     values = list(data.values())
#
#     # –°—Ç–≤–æ—Ä—é—î–º–æ –µ–º–±–µ–¥—ñ–Ω–≥–∏ –¥–ª—è –∫–ª—é—á—ñ–≤
#     key_embeddings = model.encode(keys, convert_to_tensor=True)
#     message_embedding = model.encode(message, convert_to_tensor=True)
#
#     # –û–±—á–∏—Å–ª—é—î–º–æ —Å—Ö–æ–∂—ñ—Å—Ç—å –∫–æ—Å–∏–Ω—É—Å–æ–º
#     cos_scores = util.cos_sim(message_embedding, key_embeddings)[0]
#
#     # –í–∏–±–∏—Ä–∞—î–º–æ —Ç–æ–ø-k –Ω–∞–π–±—ñ–ª—å—à —Å—Ö–æ–∂–∏—Ö
#     top_results = np.argpartition(-cos_scores, range(top_k))[:top_k]
#
#     results = []
#     for idx in top_results:
#         results.append({
#             "key": keys[idx],
#             "value": values[idx],
#             "similarity": float(cos_scores[idx])
#         })
#
#     # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Å—Ö–æ–∂—ñ—Å—Ç—é
#     results = sorted(results, key=lambda x: x['similarity'], reverse=True)
#
#     return results

